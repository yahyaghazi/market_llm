"""
Script de test pour l'int√©gration Ollama
Teste la connexion, les mod√®les et la g√©n√©ration d'analyses
"""
import requests
import json
import time
from datetime import datetime


BASE_URL = 'http://localhost:5000'


def print_header(title):
    """Affiche un en-t√™te format√©"""
    print("\n" + "="*70)
    print(f"  {title}")
    print("="*70)


def test_health_check():
    """Test du health check avec statut Ollama"""
    print_header("TEST 1: Health Check + Statut Ollama")
    
    try:
        response = requests.get(f'{BASE_URL}/health', timeout=5)
        
        if response.status_code == 200:
            data = response.json()
            print("‚úÖ API op√©rationnelle")
            print(f"\nüìä Informations:")
            print(f"   Status: {data.get('status')}")
            print(f"   Version: {data.get('version')}")
            print(f"   Service: {data.get('service')}")
            
            ollama_info = data.get('ollama', {})
            print(f"\nü§ñ Ollama:")
            print(f"   Disponible: {'‚úÖ OUI' if ollama_info.get('available') else '‚ùå NON'}")
            print(f"   Mod√®le d√©faut: {ollama_info.get('default_model')}")
            
            if not ollama_info.get('available'):
                print("\n‚ö†Ô∏è  ATTENTION: Ollama n'est pas accessible!")
                print("   1. V√©rifiez qu'Ollama est d√©marr√©: ollama serve")
                print("   2. V√©rifiez le port: http://localhost:11434")
                
        else:
            print(f"‚ùå Erreur {response.status_code}")
            
    except requests.exceptions.ConnectionError:
        print("‚ùå Impossible de se connecter √† l'API")
        print("   Assurez-vous que le serveur est d√©marr√©: python app_ollama.py")
    except Exception as e:
        print(f"‚ùå Erreur: {e}")


def test_list_models():
    """Test du listing des mod√®les Ollama"""
    print_header("TEST 2: Liste des Mod√®les Ollama")
    
    try:
        response = requests.get(f'{BASE_URL}/ollama/models', timeout=10)
        
        if response.status_code == 200:
            data = response.json()
            models = data.get('models', [])
            
            print(f"‚úÖ {data.get('count')} mod√®le(s) disponible(s)")
            print(f"\nüìã Liste:")
            for i, model in enumerate(models, 1):
                marker = "‚≠ê" if model == data.get('default') else "  "
                print(f"   {marker} {i}. {model}")
            
            if not models:
                print("‚ö†Ô∏è  Aucun mod√®le trouv√©!")
                print("   T√©l√©chargez un mod√®le: ollama pull gemma3:4b")
                
        elif response.status_code == 503:
            print("‚ùå Ollama non accessible")
            data = response.json()
            print(f"   {data.get('error')}")
            print(f"   {data.get('details')}")
        else:
            print(f"‚ùå Erreur {response.status_code}")
            
    except Exception as e:
        print(f"‚ùå Erreur: {e}")


def test_simple_analysis_ollama():
    """Test d'analyse avec Ollama"""
    print_header("TEST 3: Analyse Simple avec Ollama")
    
    data = {
        "products": ["iPhone 15 Pro", "Samsung Galaxy S24 Ultra"],
        "sector": "Smartphones Premium",
        "ollama": {
            "use_ollama": True,
            "model": "gemma3:4b",
            "temperature": 0.7,
            "top_p": 0.9,
            "max_tokens": 2000
        }
    }
    
    print(f"\nüì§ Envoi de la requ√™te...")
    print(f"   Produits: {', '.join(data['products'])}")
    print(f"   Secteur: {data['sector']}")
    print(f"   Mod√®le: {data['ollama']['model']}")
    print(f"   Temperature: {data['ollama']['temperature']}")
    print(f"\n‚è≥ G√©n√©ration en cours (peut prendre 1-3 minutes avec LLM)...")
    
    start_time = time.time()
    
    try:
        response = requests.post(
            f'{BASE_URL}/api/analyze',
            json=data,
            timeout=300  # 5 minutes
        )
        
        elapsed = time.time() - start_time
        
        if response.status_code == 200:
            result = response.json()
            
            print(f"\n‚úÖ Analyse r√©ussie en {elapsed:.1f}s!")
            print(f"\nüìÑ PDF g√©n√©r√©: {result['pdf_filename']}")
            print(f"üîó URL: {BASE_URL}{result['pdf_url']}")
            
            analysis = result.get('analysis', {})
            print(f"\nüìä R√©sultats:")
            print(f"   Secteur: {analysis.get('sector')}")
            print(f"   Date: {analysis.get('date')}")
            print(f"   Produits analys√©s: {analysis.get('products_count')}")
            print(f"   Ollama utilis√©: {analysis.get('ollama_used')}")
            print(f"   Mod√®le: {analysis.get('model')}")
            
            print(f"\nüí∞ M√©triques par produit:")
            for product in analysis.get('products', []):
                print(f"\n   ‚Ä¢ {product['name']}")
                print(f"     Part de march√©: {product['market_share']:.1f}%")
                print(f"     Prix: {product['price']:.0f}‚Ç¨")
                print(f"     Satisfaction: {product['satisfaction']:.1f}/5")
                print(f"     Croissance: {product['growth']:+.1f}%")
            
            print(f"\nüìù R√©sum√© ex√©cutif:")
            summary = analysis.get('summary', '')
            print(f"   {summary[:200]}...")
            
            return result['pdf_filename']
            
        else:
            print(f"\n‚ùå Erreur {response.status_code}")
            error_data = response.json()
            print(f"   {error_data.get('error')}")
            if 'details' in error_data:
                print(f"   D√©tails: {error_data['details']}")
                
    except requests.exceptions.Timeout:
        print(f"\n‚ùå Timeout apr√®s {elapsed:.1f}s")
        print("   Le LLM prend trop de temps. Solutions:")
        print("   1. Utiliser un mod√®le plus l√©ger (deepseek-r1:7b)")
        print("   2. R√©duire max_tokens")
        print("   3. Augmenter le timeout")
    except Exception as e:
        print(f"\n‚ùå Erreur: {e}")
    
    return None


def test_fallback_mode():
    """Test du mode fallback (sans Ollama)"""
    print_header("TEST 4: Mode Fallback (Simulation)")
    
    data = {
        "products": ["Produit A", "Produit B"],
        "sector": "Test Secteur",
        "ollama": {
            "use_ollama": False  # Forcer fallback
        }
    }
    
    print(f"\nüì§ Envoi en mode simulation...")
    print(f"‚è≥ G√©n√©ration (rapide, simulation)...")
    
    start_time = time.time()
    
    try:
        response = requests.post(
            f'{BASE_URL}/api/analyze',
            json=data,
            timeout=60
        )
        
        elapsed = time.time() - start_time
        
        if response.status_code == 200:
            result = response.json()
            
            print(f"\n‚úÖ Simulation r√©ussie en {elapsed:.1f}s!")
            print(f"üìÑ PDF: {result['pdf_filename']}")
            
            analysis = result.get('analysis', {})
            print(f"\nüìä Mode utilis√©: {'Simulation' if not analysis.get('ollama_used') else 'Ollama'}")
            
            return result['pdf_filename']
        else:
            print(f"\n‚ùå Erreur {response.status_code}")
            
    except Exception as e:
        print(f"\n‚ùå Erreur: {e}")
    
    return None


def test_different_temperatures():
    """Test avec diff√©rentes temp√©ratures"""
    print_header("TEST 5: Comparaison Temp√©ratures")
    
    temperatures = [0.2, 0.7, 1.5]
    
    print("\nüå°Ô∏è  Test avec 3 temp√©ratures diff√©rentes:")
    print("   0.2 = Factuel/D√©terministe")
    print("   0.7 = √âquilibr√© (d√©faut)")
    print("   1.5 = Cr√©atif")
    
    for temp in temperatures:
        print(f"\n{'‚îÄ'*50}")
        print(f"üå°Ô∏è  Temperature: {temp}")
        
        data = {
            "products": ["Produit Test"],
            "sector": "Test",
            "ollama": {
                "use_ollama": True,
                "model": "gemma3:4b",
                "temperature": temp,
                "max_tokens": 500  # Court pour rapidit√©
            }
        }
        
        try:
            start = time.time()
            response = requests.post(
                f'{BASE_URL}/api/analyze',
                json=data,
                timeout=180
            )
            elapsed = time.time() - start
            
            if response.status_code == 200:
                print(f"   ‚úÖ Succ√®s en {elapsed:.1f}s")
            else:
                print(f"   ‚ùå Erreur {response.status_code}")
                
        except Exception as e:
            print(f"   ‚ùå Erreur: {e}")


def test_download(filename):
    """Test du t√©l√©chargement"""
    if not filename:
        print("\n‚ö†Ô∏è  Pas de fichier √† t√©l√©charger")
        return
    
    print_header("TEST 6: T√©l√©chargement PDF")
    
    print(f"\nüì• T√©l√©chargement: {filename}")
    
    try:
        response = requests.get(f'{BASE_URL}/api/download/{filename}', timeout=10)
        
        if response.status_code == 200:
            output_path = f'test_download_{filename}'
            with open(output_path, 'wb') as f:
                f.write(response.content)
            
            print(f"‚úÖ PDF t√©l√©charg√©!")
            print(f"üìÅ Sauvegard√©: {output_path}")
            print(f"üìä Taille: {len(response.content) / 1024:.1f} KB")
        else:
            print(f"‚ùå Erreur {response.status_code}")
            
    except Exception as e:
        print(f"‚ùå Erreur: {e}")


def main():
    """Fonction principale"""
    print("\n" + "="*70)
    print(" "*15 + "üß™ SUITE DE TESTS OLLAMA")
    print("="*70)
    print("\n‚ö†Ô∏è  Pr√©-requis:")
    print("   1. Ollama d√©marr√©: ollama serve")
    print("   2. Mod√®le t√©l√©charg√©: ollama pull gemma3:4b")
    print("   3. API lanc√©e: python app_ollama.py")
    print("\n" + "="*70)
    
    input("\nAppuyez sur Entr√©e pour commencer les tests...")
    
    # Test 1: Health check
    test_health_check()
    
    # Test 2: Liste mod√®les
    test_list_models()
    
    # Demander si on continue avec Ollama
    print("\n" + "‚îÄ"*70)
    continue_ollama = input("\nü§ñ Continuer avec les tests Ollama (lents, 1-3 min)? [o/N]: ")
    
    if continue_ollama.lower() in ['o', 'oui', 'y', 'yes']:
        # Test 3: Analyse Ollama
        filename = test_simple_analysis_ollama()
        
        # Test 4: Fallback
        test_fallback_mode()
        
        # Test 5: Temp√©ratures (optionnel)
        test_temps = input("\nüå°Ô∏è  Tester diff√©rentes temp√©ratures (lent)? [o/N]: ")
        if test_temps.lower() in ['o', 'oui', 'y', 'yes']:
            test_different_temperatures()
        
        # Test 6: T√©l√©chargement
        if filename:
            test_download(filename)
    else:
        print("\n‚è≠Ô∏è  Tests Ollama ignor√©s")
        
        # Test fallback uniquement
        filename = test_fallback_mode()
        if filename:
            test_download(filename)
    
    # R√©sum√©
    print("\n" + "="*70)
    print(" "*20 + "‚úÖ TESTS TERMIN√âS")
    print("="*70)
    print("\nüí° Conseils:")
    print("   ‚Ä¢ V√©rifiez les PDFs g√©n√©r√©s dans le dossier 'reports/'")
    print("   ‚Ä¢ Ajustez les hyperparam√®tres selon vos besoins")
    print("   ‚Ä¢ Utilisez un mod√®le plus l√©ger si timeouts fr√©quents")
    print("\nüìö Documentation: Voir OLLAMA_GUIDE.md")
    print("\n")


if __name__ == '__main__':
    main()